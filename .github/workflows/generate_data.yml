name: Continuous Data Generation
on:
  push:
    branches: [ master, main ]
  workflow_dispatch:

permissions:
  contents: write
  actions: write

jobs:
  generate:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.PAT_TOKEN || secrets.GITHUB_TOKEN }}

    - name: Download NNUE Networks
      run: |
        cd src
        wget https://tests.stockfishchess.org/api/nn/nn-c288c895ea92.nnue
        wget https://tests.stockfishchess.org/api/nn/nn-37f18f62d772.nnue

    - name: Build Engine (Linux)
      run: |
        cd src
        g++ -O3 -std=c++17 -Wall -fno-exceptions -DNDEBUG -DIS_64BIT -DUSE_PTHREADS -march=native \
        -Wno-unused-variable -Wno-unused-but-set-variable \
        benchmark.cpp bitboard.cpp evaluate.cpp main.cpp misc.cpp movegen.cpp movepick.cpp \
        position.cpp search.cpp thread.cpp timeman.cpp tt.cpp uci.cpp ucioption.cpp \
        tune.cpp syzygy/tbprobe.cpp nnue/nnue_accumulator.cpp nnue/nnue_misc.cpp \
        nnue/network.cpp nnue/features/half_ka_v2_hm.cpp nnue/features/full_threats.cpp \
        engine.cpp score.cpp memory.cpp nextfish_strategy.cpp nextfish_timeman.cpp \
        datagen.cpp -o ../nextfish -lpthread -latomic

    - name: Run Datagen (Parallel High-Quality Batch)
      run: |
        chmod +x nextfish
        python3 preprocess_pgn.py
        
        # Chạy song song và chuyển hướng log để không bị đè nhau trên console
        echo "Starting Core 1..."
        ./nextfish datagen nodes 8000 games 200 book book_moves.txt out data1.binpack > log1.txt &
        echo "Starting Core 2..."
        ./nextfish datagen nodes 8000 games 200 book book_moves.txt out data2.binpack > log2.txt &
        
        # Theo dõi log của Core 1 (đại diện)
        sleep 5
        tail -f log1.txt &
        PID_TAIL=$!
        
        wait
        kill $PID_TAIL || true
        
        # Tạo file batch mới
        cat data1.binpack data2.binpack > new_batch.binpack
        
        # Kiểm tra dung lượng
        FILE="nextfish_data.binpack"
        CURRENT_SIZE=0
        if [ -f "$FILE" ]; then
          CURRENT_SIZE=$(stat -c%s "$FILE")
        fi
        
        NEW_SIZE=$(stat -c%s "new_batch.binpack")
        TOTAL_SIZE=$((CURRENT_SIZE + NEW_SIZE))
        
        if [ "$TOTAL_SIZE" -gt 94371840 ]; then
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          mv "$FILE" "data_${TIMESTAMP}.binpack"
          mv new_batch.binpack "$FILE"
        else
          cat new_batch.binpack >> "$FILE"
          rm new_batch.binpack
        fi
        
        rm data1.binpack data2.binpack book_moves.txt preprocess_pgn.py log1.txt log2.txt

    - name: Commit & Push Data
      id: push_step
      env:
        GH_TOKEN: ${{ secrets.PAT_TOKEN || secrets.GITHUB_TOKEN }}
      run: |
        git config --global user.name 'Nextfish Data Bot'
        git config --global user.email 'bot@nextfish.ai'
        
        # Đảm bảo đồng bộ với remote trước khi push
        git fetch origin master
        git rebase origin/master || (git rebase --abort && git pull --rebase origin master)
        
        git add *.binpack
        
        if git diff --staged --quiet; then
          echo "No new data to commit"
        else
          git commit -m "Add new training data [gen]"
          git push https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }}.git HEAD:master
        fi

    - name: Trigger Next Cycle
      if: always() && (steps.push_step.outcome == 'success' || steps.push_step.outcome == 'skipped')
      env:
        GH_TOKEN: ${{ secrets.PAT_TOKEN || secrets.GITHUB_TOKEN }}
      run: |
        echo "Waiting before triggering next run..."
        sleep 15
        gh workflow run generate_data.yml --ref ${{ github.ref_name }} || echo "Auto-trigger failed, but process may continue on next push."
